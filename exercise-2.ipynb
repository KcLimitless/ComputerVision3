{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision \n",
    "\n",
    "# Exercise 2: Basic Image Processing With OpenCV\n",
    "\n",
    "- TU Chemnitz\n",
    "    - Fak. für Informatik\n",
    "        - Professur Künstliche Intelligenz\n",
    "            - Lehre\n",
    "                - Bildverstehen\n",
    "     \n",
    "Contact:\n",
    "* julien dot vitay at informatik dot tu-chemnitz dot de\n",
    "* abbas dot al-ali at informatik dot tu-chemnitz dot de\n",
    "\n",
    "Course web page:\n",
    "[https://www.tu-chemnitz.de/informatik/KI/edu/biver/](https://www.tu-chemnitz.de/informatik/KI/edu/biver/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Basic Image Processing With OpenCV\n",
    "\n",
    "## 1. OpenCV Computer Vision Library\n",
    "\n",
    "<img src=\"img/opencv.jpg\" alt=\"img/opencv.jpg\" width=\"600\"/>\n",
    "\n",
    "- Originally developed by Intel, now maintained by a fundation (BSD license)\n",
    "\n",
    "- The library is written in C++ but you can access it from Python:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "```\n",
    "\n",
    "- The official website of OpenCV is at [http://opencv.org](http://opencv.org)\n",
    "\n",
    "- The official documentation of OpenCV( C++ and Python) is at <http://docs.opencv.org/3.1.0/>\n",
    "\n",
    "- Python tutorials are at <https://docs.opencv.org/3.1.0/d6/d00/tutorial_py_root.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic IO\n",
    "\n",
    "### 2.A. Loading An Image\n",
    "\n",
    "The function `imread()` can be used to load an image from a file:\n",
    "\n",
    "```python\n",
    "img = cv2.imread('path/to/img.ext', FLAG)\n",
    "```\n",
    "- First argument is the path to the file\n",
    "- Second argument( optional) could be:\n",
    "\n",
    "    - `cv2.IMREAD_COLOR` (or 1): Loads a color image. Any transparency of image will be neglected. It is the default flag.\n",
    "    - `cv2.IMREAD_GRAYSCALE` (or 0): Loads image in grayscale mode\n",
    "    - `cv2.IMREAD_UNCHANGED` (or -1): Loads image as such including alpha channel\n",
    "    - ...\n",
    "\n",
    "- Images loaded by OpenCV are Numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.B Saving An Image\n",
    "\n",
    "Saving a numpy array (2D or 3D) as an image to the disk can be done using `imwrite`:\n",
    "\n",
    "```python\n",
    "cv2.imwrite('path/to/img.ext', img)\n",
    "```\n",
    "\n",
    "Most image extensions can be used: jpg, png, bmp..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.C. Displaying An Image\n",
    "\n",
    "- The simplest is to use matplotlib:\n",
    "\n",
    "```python\n",
    "plt.imshow(img [, options] )\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- OpenCV has an `imshow` function, but it is not practical.\n",
    "\n",
    "- If you want to display a color image, you have to convert it to RGB (more on that later):\n",
    "\n",
    "```python\n",
    "img_RGB = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_RGB)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now:**\n",
    "\n",
    "- Read the image file `lena.jpg` from the disk to the two variables\n",
    "    + `img_color` as a colored and\n",
    "    + `img_gray` as a gray-scaled image\n",
    "    \n",
    "- Of the two variables tell:\n",
    "    + the type of the variable\n",
    "    + the shape of the NumPy array\n",
    "    + the data type of the elemets in the array\n",
    "    + the minimum and maximum value\n",
    "\n",
    "- Save the colored image to the disk in `lena-colored.jpg`\n",
    "- Save the grayscale image to the disk in `lena-gray.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from __future__ import print_function\n",
    "\n",
    "#import matplotlib\n",
    "#matplotlib.use('TKAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (3971834440.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [8]\u001b[1;36m\u001b[0m\n\u001b[1;33m    img_color = cv2.cvtColor(D\\New Start\\2nd_Sem\\IU\\IU_Ex\\exercise-2\\exercise-2\\lena.jpg, cv2.COLOR_BGR2RGB)\u001b[0m\n\u001b[1;37m                                                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "from __future__ import print_function\n",
    "\n",
    "#import matplotlib\n",
    "#matplotlib.use('TKAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# In color\n",
    "img_color = cv2.cvtColor(D\\New Start\\2nd_Sem\\IU\\IU_Ex\\exercise-2\\exercise-2\\lena.jpg, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_color)\n",
    "plt.show()\n",
    "\n",
    "# In grayscale\n",
    "img_gray = cv2.imread(D\\New Start\\2nd_Sem\\IU\\IU_Ex\\exercise-2\\exercise-2\\lena.jpg, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.imshow(img_gray)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# for both print type, shape, data type, min and max\n",
    "\n",
    "...\n",
    "\n",
    "# write both to the the disk\n",
    "# img_color --> 'lena-colored.jpg'\n",
    "# img_gray --> 'lena-gray.jpg'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Images From Numpy Arrays\n",
    "\n",
    "- Numpy arrays of shape (height, width) or (height, width, 3) and dtype `np.uint8` can be saved as images\n",
    "\n",
    "- If the array has another dtype, the values will be casted to `np.uint8`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.A. Creating A Grayscale Image\n",
    "\n",
    "Create a grayscale image of size 640x480, with a black background and a white 100x100 square in the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a black image 640x480\n",
    "img_black = ...\n",
    "\n",
    "img_white_square = ...\n",
    "\n",
    "# write both the the disk\n",
    "# img_black --> 'black.jpg' \n",
    "# img_white_square -->'white-square.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.B. Creating A Color Image\n",
    "\n",
    "- Create a color image of size 640x480, with a white background and a red 100x100 square in the center\n",
    "\n",
    "- Create a color image of size 640x480, with random pixels\n",
    "\n",
    "**Beware:** the order of the colors in the third dimension when writing is BGR, not RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a white RGB-image 640x480\n",
    "img_white = ...\n",
    "img_red_square = ...\n",
    "img_noise = ...\n",
    "\n",
    "# write all three to the the disk\n",
    "# img_white --> 'white.jpg', \n",
    "# img_red_square --> 'red_square.jpg'\n",
    "# img_noise --> 'noise.jpg'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Color Spaces\n",
    "\n",
    "Converting between color spaces\n",
    "\n",
    "- The default colorspace in OpenCV is BGR.\n",
    "\n",
    "- You can convert images from and to many color spaces with `cvtColor`, e.g.:\n",
    "\n",
    "```python\n",
    "img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "```\n",
    "\n",
    "- You can get a list of all possible color conversions by typing:\n",
    "\n",
    "```python \n",
    "for flag in dir(cv2):\n",
    "    if flag.startswith('COLOR_'):\n",
    "        print(flag)\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "...\n",
    "COLOR_BGRA2GRAY\n",
    "COLOR_BGRA2RGB\n",
    "COLOR_BGRA2RGBA\n",
    "...\n",
    "COLOR_GRAY2BGR\n",
    "...\n",
    "COLOR_GRAY2BGRA\n",
    "COLOR_GRAY2RGB\n",
    "COLOR_GRAY2RGBA\n",
    "COLOR_HLS2BGR\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert the lena image to HSV (hue-saturation-value) and save the saturation as a grayscale image\n",
    "- Saturate the image by setting the S channel to 255 and save it as a color image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read lena.jpg in color\n",
    "# lena_bgr <-- 'lena.jpg'\n",
    "...\n",
    "\n",
    "# Convert to HSV\n",
    "# lena_hsv <-- lena_bgr\n",
    "...\n",
    "\n",
    "# write the saturation to the disk\n",
    "# saturation --> 'lena-saturation.jpg'\n",
    "\n",
    "# saturate the image\n",
    "\n",
    "lena_saturated = ...\n",
    "\n",
    "# write the result to the disk\n",
    "# lena_saturated --> 'lena-saturated.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Point Operation: Thresholding\n",
    "\n",
    "- The thresholding operation is to create a *destination* image $g$ from a *source* image $f$ by replacing each pixel of the original image $f$ with 255 if the pixel intensity is above a threshold $T$, and by 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    g(i, j) = \\begin{cases}\n",
    "                255 \\quad \\text{ if } f(i, j) > T \\\\\n",
    "                0   \\quad \\text{ otherwise.}\n",
    "            \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply a threshold $T=127$ on the grayscale image of Lena `img_gray` and save the result to `lena-thresholded.jpg`. You can either:\n",
    "    + Iterate over the two coordinates and set the pixel intensity of the target image/array:\n",
    "\n",
    "    ```python\n",
    "    for i in range(img_gray.shape[0]):\n",
    "        for j in range(img_gray.shape[1]):\n",
    "            thresholded[i, j] = ...\n",
    "    ```\n",
    "    \n",
    "    + Or you use boolean arrays for sub-indexing:\n",
    "\n",
    "    ```python\n",
    "    thresholded[img_gray > T] = ...\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the lena image\n",
    "T = 127\n",
    "# thresholded <-- img_gray\n",
    "\n",
    "thresholded = ...\n",
    "\n",
    "# write the result to the disk\n",
    "# thresholded --> 'lena-thresholded.jpg'\n",
    "...\n",
    "\n",
    "# or using sub-indexing\n",
    "thresholded = ...\n",
    "\n",
    "# write the result to the disk\n",
    "# thresholded --> 'lena-thresholded2.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modify the thresholding procedure so that above-threshold pixels are converted to red, not white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the lena image reddish \n",
    "red_lena = ...\n",
    "\n",
    "# write the result to the disk\n",
    "# red_lena --> 'lena-red.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another solution to threshold an image is to use the OpenCV function `threshold`:\n",
    "\n",
    "```python\n",
    "ret, th = cv2.threshold(img_gray,thresh=127, \n",
    "                        maxval=255, type=cv2.THRESH_BINARY)\n",
    "```\n",
    "\n",
    "- There are many threshold types to investigate:\n",
    "\n",
    "![img/threshold.jpg](img/threshold.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the lena image using cv2.threshold()\n",
    "\n",
    "ret, thresholded = ...\n",
    "\n",
    "# write the result to the disk\n",
    "# thresholded --> 'lena-thresholded3.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply thresholding on the `sudoku.jpg` image. Try to find a threshold that works to extract all printed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the sudoku image\n",
    "# sudoku_gray <-- cv2.imread('sudoku.jpg\n",
    "sudoku_gray = ...\n",
    "ret, thresholded = ...\n",
    "# write the result to the disk\n",
    "# thresholded --> 'sudoku-thresholded.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does it work well? Why is it difficult to find a suitable threshold value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now: apply the adaptive thresholding on the `sudoku.jpg` image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive threshold for the sudoku image\n",
    "thresholded2 = cv2.adaptiveThreshold(sudoku_gray, 255\n",
    "            , cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# write the result to the disk\n",
    "# thresholded2 --> 'sudoku-thresholded2.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Global Operation: Histogram Equalization\n",
    "\n",
    "- Build and plot an histogram $h(I)$ of pixel intensities in the grayscale lena\n",
    "\n",
    "- Build and plot the corresponding cumulative histogram $c(I)$\n",
    " \n",
    "$$ c(I) = \\frac{1}{N} \\sum_{i=0}^I h(i) = c(I-1) + \\frac{1}{N} h(I) $$\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"img/lena-histo.png\" alt=\"img/lena-histo.png\\\" width=\"300\"/>\n",
    "</td>\n",
    "<td>\n",
    "<img src=\"img/lena-cumhisto.png\" alt=\"img/lena-cumhisto.png\" width=\"300\"/>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a histogram of pixel intensities\n",
    "hist = ...\n",
    "\n",
    "# Compute the cumulative histogram\n",
    "cum_hist = ...\n",
    "\n",
    "# plot the results\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)    \n",
    "plt.plot(...)\n",
    "plt.title('Histogram')\n",
    "plt.xlabel(...)\n",
    "plt.ylabel(...)\n",
    "\n",
    "plt.subplot(1,2,2)    \n",
    "plt.plot(...)\n",
    "plt.title('Cumulative histogram')\n",
    "plt.xlabel(...)\n",
    "plt.ylabel(...)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Equalize the grayscale lena and save it to disk. Compare.\n",
    "\n",
    "$$ g(i, j) = 255 \\times c(f(i, j)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equalize the histogram\n",
    "equalized = ...\n",
    "\n",
    "for i in ...:\n",
    "    for j in ...:\n",
    "        equalized[i, j] = ...\n",
    "\n",
    "# write the result to the disk\n",
    "# equalized --> 'lena-equalized.jpg'        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OpenCV has a `equalizeHist(img_gray)` method that does the same operation. Compare its result with yours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using OpenCV:\n",
    "\n",
    "equalized = ...\n",
    "\n",
    "# write the result to the disk\n",
    "# equalized --> 'lena-equalized.jpg' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Local Operation: Locally Adaptive Histogram Equalization\n",
    "\n",
    "- The problem with histogram equalization is that it uses **global** information about the image\n",
    "\n",
    "- **Locally adaptive histogram equalization** (CLAHE) performs histogram equalization **locally** around each pixel.\n",
    "\n",
    "<img src=\"img/clahe.png\" alt=\"img/clahe.png\" width=\"300\"/>\n",
    "<!-- ![](img/clahe.png) -->\n",
    "\n",
    "$$ c(f(i, j)) = d_1(i, j) c_1(f(i, j)) + d_2(i, j) c_2(f(i, j)) + d_3(i, j) c_3(f(i, j)) + d_4(i, j) c_4(f(i, j)) $$\n",
    "\n",
    "- OpenCV allows to apply directly this algorithm on an image:\n",
    "\n",
    "```python\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "cl = clahe.apply(img)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply the CLAHE algorihm on the images lena and sudoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAHE\n",
    "...\n",
    "\n",
    "# apply to Lena (img_gray) and save\n",
    "# clahe_lena -->  'lena-clahe.jpg' \n",
    "...\n",
    "# apply to sudoku (sudoku_gray) and save\n",
    "# clahe_sudoku -->  'sudoku-clahe.jpg' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Color Filters\n",
    "\n",
    "We want to filter out the feathers on Lena's hat. Their color has a hue between 120 and 160.\n",
    "\n",
    "- Create a color image where only the feathers are colored as in the original, the rest being gray.\n",
    "\n",
    "The algorithm is basically:\n",
    "\n",
    "1. Convert the color image to HSV.\n",
    "\n",
    "2. Convert the gray image to BGR to store the result.\n",
    "\n",
    "3. For all pixels:    \n",
    "    + If the hue is between 120 and 160, write the original BGR color vector to the result image.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a first try, make a double for-loop over the pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hsv  <-- img_color\n",
    "# gray <--  img_color\n",
    "hsv = ...\n",
    "gray = ...\n",
    "\n",
    "result = ...\n",
    "\n",
    "hue_min = 120\n",
    "hue_max = 160\n",
    "\n",
    "for i in ... :\n",
    "    for j in ... :\n",
    "        if hsv[...] ... :\n",
    "            result[...] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a second try, try to think about what this function does:\n",
    "\n",
    "```python\n",
    "hue = hsv[:, :, 0]\n",
    "np.bitwise_and(hue > 120, hue < 160)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hsv  <-- img_color\n",
    "# gray <--  img_color\n",
    "hsv = ...\n",
    "gray = ...\n",
    "\n",
    "result = ...\n",
    "\n",
    "hue_min = 120\n",
    "hue_max = 160\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are done, put your code into a function, we will need it later:\n",
    "\n",
    "```python\n",
    "def hue_filter(img, hue_min, hue_max):\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the violet color\n",
    "def hue_filter(img_color, hue_min, hue_max):\n",
    "    ...\n",
    "    \n",
    "    return result\n",
    "\n",
    "# call the function\n",
    "violet_filtered = ...\n",
    "# write to the disk\n",
    "# violet_filtered --> 'lena-violet-filtered.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Videos\n",
    "\n",
    "### 9.A. Opening A Video\n",
    "\n",
    "You can read a video frame-by-frame with the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('video.ogv')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        #frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('frame', frame)\n",
    "    else:\n",
    "        break\n",
    "    k = cv2.waitKey(5) & 0xFF # Sleep 5 ms\n",
    "    if k == 27: # Press ESC to close\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Put the code in a script `vread.py` and run it from a terminal\n",
    "\n",
    "```bash\n",
    "$ python vread.py\n",
    "```\n",
    "\n",
    "- Open the script again and remove the comment mark `#` in the `if` statement in odrer to call the function `frame = cv2.cvtColor()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can read different video format supported by ffmpeg/gstreamer on Linux:\n",
    "\n",
    "    * H264 (.mp4)\n",
    "    * WebM (.webm)\n",
    "    * AVI (.avi)\n",
    "    * Theora (.ogv)\n",
    "    * DivX, WMV...\n",
    "\n",
    "- In the B202, you have only access to `.ogv` videos (non-free codecs issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.B. Writing A Video\n",
    "\n",
    "Saving a video is just as easy. Copy the code to a script `vwrite.py` and run it:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# vwrite.py: writing a video\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# create VideoWriter object\n",
    "out = cv2.VideoWriter( \n",
    "    filename='video-square.ogv', \n",
    "    fourcc=cv2.VideoWriter_fourcc(*'THEO'), \n",
    "    fps=30.0, \n",
    "    frameSize=(560,320)\n",
    ")\n",
    "\n",
    "\n",
    "for f in range(90):\n",
    "    frame = np.zeros((320,560), np.uint8)\n",
    "    frame[160 - 50 + 2*f: 160 + 50 + 2*f, \n",
    "         280 - 50 + 2*f: 280 + 50 + 2*f] = 255\n",
    "    out.write(cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "out.release()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You only need to choose the right codec for the `fourcc` argument.\n",
    "\n",
    "    + `'H264'` for mp4.\n",
    "    + `'XVID'` for avi.\n",
    "    + `'THEO'` for theora. \n",
    "\n",
    "- **Only Theora works in B202**\n",
    "- See <http://www.fourcc.org>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exercises\n",
    "\n",
    "### 10.A. Processing Videos\n",
    "\n",
    "- Read the given video `video.ogv` and save the grayscale version in `video-gray.ogv`.\n",
    "\n",
    "- Apply a color filter on each frame and filter the blue color (hue between 100 and 130).\n",
    "\n",
    "- Compare the time needed for this last conversion when using the double for-loops, and the `numpy.bitwise_and` method.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
